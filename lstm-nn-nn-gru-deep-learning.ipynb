{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y_train.csv', 'sample_submission.csv', 'X_train.csv', 'X_test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,train_test_split\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.optimizers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "# Input data files are available in the \"Data/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"Data\"))\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "K.set_session(sess)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "xtrain = pd.read_csv('Data/X_train.csv')\n",
    "ytrain = pd.read_csv('Data/y_train.csv')\n",
    "test=pd.read_csv(\"Data/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "2be341a2e26f22365d8ea8cac8e2f33d0328a6dd"
   },
   "outputs": [],
   "source": [
    "### feature extraction of orientation, angular_velocity, linear_acceleration, velocity_to_acceleration and velocity_linear_acceleration\n",
    "def feature_extraction(raw_frame):\n",
    "    raw_frame['orientation'] = raw_frame['orientation_X'] + raw_frame['orientation_Y'] + raw_frame['orientation_Z']+ raw_frame['orientation_W']\n",
    "    raw_frame['angular_velocity'] = raw_frame['angular_velocity_X'] + raw_frame['angular_velocity_Y'] + raw_frame['angular_velocity_Z']\n",
    "    raw_frame['linear_acceleration'] = raw_frame['linear_acceleration_X'] + raw_frame['linear_acceleration_Y'] + raw_frame['linear_acceleration_Y']\n",
    "    raw_frame['velocity_to_acceleration'] = raw_frame['angular_velocity'] / raw_frame['linear_acceleration']\n",
    "    raw_frame['velocity_linear_acceleration'] = raw_frame['linear_acceleration'] * raw_frame['angular_velocity']\n",
    "    return raw_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "7da090c42eaca5fd72a988b697b6a14f86e508d3"
   },
   "outputs": [],
   "source": [
    "xtrain = feature_extraction(xtrain)\n",
    "test = feature_extraction(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "123c9c83df733a4a1d77dd6a372fb9ffecca8acd"
   },
   "outputs": [],
   "source": [
    "### more feature extraction with mean, mode, std, variance, min, max and so on...\n",
    "\n",
    "def feature_extraction_more(raw_frame):\n",
    "    frame = pd.DataFrame([])\n",
    "    for col in raw_frame.columns[3:]:\n",
    "        frame[col + '_mean'] = raw_frame.groupby(['series_id'])[col].mean()\n",
    "        frame[col + '_std'] = raw_frame.groupby(['series_id'])[col].std()\n",
    "        frame[col + '_var'] = raw_frame.groupby(['series_id'])[col].var()\n",
    "        frame[col + '_sem'] = raw_frame.groupby(['series_id'])[col].sem()\n",
    "        frame[col + '_max'] = raw_frame.groupby(['series_id'])[col].max()\n",
    "        frame[col + '_min'] = raw_frame.groupby(['series_id'])[col].min()\n",
    "        frame[col + '_max_to_min'] = frame[col + '_max'] / frame[col + '_min']\n",
    "        frame[col + '_max_minus_min'] = frame[col + '_max'] - frame[col + '_min']\n",
    "        frame[col + '_std_to_var'] = frame[col + '_std'] * frame[col + '_var']\n",
    "        frame[col + '_mean_abs_change'] = raw_frame.groupby('series_id')[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "        frame[col + '_abs_max'] = raw_frame.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "fed61fdfe466dd3ec075258c87981fd546133cf7"
   },
   "outputs": [],
   "source": [
    "train_df = feature_extraction_more(xtrain)\n",
    "test_df = feature_extraction_more(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d37efc43addaf24b30e26a16c34e70f938c9c120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (3810, 165)\n",
      "test shape (3816, 165)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape\",train_df.shape)\n",
    "print(\"test shape\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "05df3ef9578f5d2f167e4777d29d2939286c32d5"
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_df = scaler.fit_transform(train_df)\n",
    "test_df = scaler.fit_transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7c0f9f9eccb75cf94d7957bcf4c341cbaf2dfcda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3810, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### lable encoding \n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(ytrain.surface)\n",
    "ytrain['surface'] = le.transform(ytrain.surface)\n",
    "train_label = to_categorical(ytrain['surface'])\n",
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "f798e6468abdf37cf1dc730156105618b6875d56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3429, 165), (381, 165), (3429, 9), (381, 9))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,val_x,train_y,val_y = train_test_split(train_df, train_label, test_size = 0.10, random_state=14)\n",
    "train_x.shape,val_x.shape,train_y.shape,val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "cf5124afe0010b4eafd32205578b44d2d824a009"
   },
   "outputs": [],
   "source": [
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "val_x = np.reshape(val_x, (val_x.shape[0], val_x.shape[1], 1))\n",
    "test_df = np.reshape(test_df, (test_df.shape[0], test_df.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "842aaef44a88062847b99f7009998650ed28d221"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3429, 165, 1), (381, 165, 1), (3816, 165, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,val_x.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "362249addb28dbd42528e72f6f63131576d5538f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_features = train_df.shape[1]\n",
    "nb_out = train_label.shape[1]\n",
    "nb_features,nb_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "7a82972642c1a0699171f14a3f50f0f4577e77e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 70,985\n",
      "Trainable params: 70,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/ist597/simple-keras-lstm-classifier-98-74\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, input_shape=((nb_features), 1)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_out, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "aec2b3f4c227ee71ac992e0dae722370ae492bf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3429 samples, validate on 381 samples\n",
      "Epoch 1/10\n",
      "3429/3429 [==============================] - 29s 8ms/step - loss: 2.0633 - acc: 0.2651 - val_loss: 1.9666 - val_acc: 0.2940\n",
      "Epoch 2/10\n",
      "3429/3429 [==============================] - 28s 8ms/step - loss: 1.9132 - acc: 0.3053 - val_loss: 1.8096 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "3429/3429 [==============================] - 27s 8ms/step - loss: 1.8482 - acc: 0.3094 - val_loss: 1.8131 - val_acc: 0.3123\n",
      "Epoch 4/10\n",
      "3429/3429 [==============================] - 28s 8ms/step - loss: 1.8094 - acc: 0.3220 - val_loss: 1.7291 - val_acc: 0.3858\n",
      "Epoch 5/10\n",
      "3429/3429 [==============================] - 27s 8ms/step - loss: 1.8191 - acc: 0.3170 - val_loss: 1.7085 - val_acc: 0.3675\n",
      "Epoch 6/10\n",
      "3429/3429 [==============================] - 27s 8ms/step - loss: 1.7927 - acc: 0.3170 - val_loss: 1.7367 - val_acc: 0.3491\n",
      "Epoch 7/10\n",
      "3429/3429 [==============================] - 27s 8ms/step - loss: 1.7331 - acc: 0.3476 - val_loss: 1.7092 - val_acc: 0.3753\n",
      "Epoch 8/10\n",
      "3429/3429 [==============================] - 26s 8ms/step - loss: 1.7021 - acc: 0.3628 - val_loss: 1.6855 - val_acc: 0.3806\n",
      "Epoch 9/10\n",
      "3429/3429 [==============================] - 27s 8ms/step - loss: 1.6877 - acc: 0.3747 - val_loss: 1.6450 - val_acc: 0.4068\n",
      "Epoch 10/10\n",
      "3429/3429 [==============================] - 27s 8ms/step - loss: 1.6795 - acc: 0.3841 - val_loss: 1.6101 - val_acc: 0.4016\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "8dfd5efcfad87835dda2dcb61833597312c4cf6f"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_df)\n",
    "prediction=np.argmax(prediction, axis=1) \n",
    "submission = pd.read_csv(\"Data/sample_submission.csv\")\n",
    "submission['surface'] = le.inverse_transform(prediction)\n",
    "submission.to_csv('lstm_38.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "69d5f94bd355d132667cb133531ad10648fe4e76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3429, 165), (381, 165), (3816, 165))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1]))\n",
    "val_x = np.reshape(val_x, (val_x.shape[0], val_x.shape[1]))\n",
    "test_df = np.reshape(test_df, (test_df.shape[0], test_df.shape[1]))\n",
    "train_x.shape,val_x.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "8ed80edff2855d3d9776df06f61846ec455e507f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 165)               27390     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 165)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 60)                9960      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 549       \n",
      "=================================================================\n",
      "Total params: 37,899\n",
      "Trainable params: 37,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## https://www.kaggle.com/kabure/titanic-eda-keras-nn-pipelines\n",
    "## Creating the model\n",
    "model = Sequential()\n",
    "\n",
    "# Inputing the first layer with input dimensions\n",
    "model.add(Dense(165, \n",
    "                activation='relu',  \n",
    "                input_dim = nb_features,\n",
    "                kernel_initializer='uniform'))\n",
    "\n",
    "# Adding an Dropout layer to previne from overfitting\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "#adding second hidden layer \n",
    "model.add(Dense(60,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu'))\n",
    "\n",
    "# Adding another Dropout layer\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "# adding the output layer that is binary [0,1]\n",
    "model.add(Dense(nb_out, activation='softmax'))\n",
    "\n",
    "#Visualizing the model\n",
    "model.summary()\n",
    "\n",
    "sgd = SGD(lr = 0.01, momentum = 0.9)\n",
    "\n",
    "# Compiling our model\n",
    "model.compile(optimizer = sgd, \n",
    "                   loss = 'categorical_crossentropy', \n",
    "                   metrics = ['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "save_best = ModelCheckpoint('cnn.hdf', save_best_only=True, \n",
    "                               monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "1af563c2f0fe9cd13dfe85106da54fcd7ce32061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3429 samples, validate on 381 samples\n",
      "Epoch 1/50\n",
      "3429/3429 [==============================] - 1s 173us/step - loss: 1.8360 - acc: 0.3622 - val_loss: 1.5213 - val_acc: 0.4567\n",
      "Epoch 2/50\n",
      "3429/3429 [==============================] - 0s 82us/step - loss: 1.5281 - acc: 0.4672 - val_loss: 1.4212 - val_acc: 0.5066\n",
      "Epoch 3/50\n",
      "3429/3429 [==============================] - 0s 79us/step - loss: 1.4167 - acc: 0.4975 - val_loss: 1.2935 - val_acc: 0.5906\n",
      "Epoch 4/50\n",
      "3429/3429 [==============================] - 0s 80us/step - loss: 1.3397 - acc: 0.5179 - val_loss: 1.1737 - val_acc: 0.6299\n",
      "Epoch 5/50\n",
      "3429/3429 [==============================] - 0s 82us/step - loss: 1.3131 - acc: 0.5232 - val_loss: 1.1397 - val_acc: 0.6430\n",
      "Epoch 6/50\n",
      "3429/3429 [==============================] - 0s 81us/step - loss: 1.2660 - acc: 0.5351 - val_loss: 1.0767 - val_acc: 0.6142\n",
      "Epoch 7/50\n",
      "3429/3429 [==============================] - 0s 82us/step - loss: 1.2056 - acc: 0.5570 - val_loss: 1.0517 - val_acc: 0.6299\n",
      "Epoch 8/50\n",
      "3429/3429 [==============================] - 0s 79us/step - loss: 1.1770 - acc: 0.5803 - val_loss: 1.0150 - val_acc: 0.6325\n",
      "Epoch 9/50\n",
      "3429/3429 [==============================] - 0s 83us/step - loss: 1.1670 - acc: 0.5818 - val_loss: 1.0048 - val_acc: 0.6535\n",
      "Epoch 10/50\n",
      "3429/3429 [==============================] - 0s 79us/step - loss: 1.1284 - acc: 0.5891 - val_loss: 1.0179 - val_acc: 0.6719\n",
      "Epoch 11/50\n",
      "3429/3429 [==============================] - 0s 80us/step - loss: 1.1230 - acc: 0.5964 - val_loss: 0.9333 - val_acc: 0.6903\n",
      "Epoch 12/50\n",
      "3429/3429 [==============================] - 0s 83us/step - loss: 1.0904 - acc: 0.6162 - val_loss: 0.9160 - val_acc: 0.6850\n",
      "Epoch 13/50\n",
      "3429/3429 [==============================] - 0s 79us/step - loss: 1.1074 - acc: 0.6063 - val_loss: 0.8980 - val_acc: 0.6772\n",
      "Epoch 14/50\n",
      "3429/3429 [==============================] - 0s 79us/step - loss: 1.0659 - acc: 0.6232 - val_loss: 0.8889 - val_acc: 0.6982\n",
      "Epoch 15/50\n",
      "3429/3429 [==============================] - 0s 79us/step - loss: 1.0854 - acc: 0.6072 - val_loss: 0.9379 - val_acc: 0.6588\n",
      "Epoch 16/50\n",
      "3429/3429 [==============================] - 0s 80us/step - loss: 1.0572 - acc: 0.6282 - val_loss: 0.9021 - val_acc: 0.6772\n",
      "Epoch 17/50\n",
      "3429/3429 [==============================] - 0s 82us/step - loss: 1.0394 - acc: 0.6296 - val_loss: 0.8842 - val_acc: 0.6745\n",
      "Epoch 18/50\n",
      "3429/3429 [==============================] - 0s 80us/step - loss: 1.0299 - acc: 0.6290 - val_loss: 0.9152 - val_acc: 0.6745\n",
      "Epoch 19/50\n",
      "3429/3429 [==============================] - 0s 81us/step - loss: 1.0060 - acc: 0.6305 - val_loss: 0.8912 - val_acc: 0.6982\n",
      "Epoch 20/50\n",
      "3429/3429 [==============================] - 0s 81us/step - loss: 0.9897 - acc: 0.6436 - val_loss: 0.8380 - val_acc: 0.7165\n",
      "Epoch 21/50\n",
      "3429/3429 [==============================] - 0s 80us/step - loss: 0.9839 - acc: 0.6442 - val_loss: 0.8227 - val_acc: 0.7060\n",
      "Epoch 22/50\n",
      "3429/3429 [==============================] - 0s 80us/step - loss: 0.9901 - acc: 0.6238 - val_loss: 0.8814 - val_acc: 0.6850\n",
      "Epoch 23/50\n",
      "3429/3429 [==============================] - 0s 82us/step - loss: 0.9829 - acc: 0.6372 - val_loss: 0.7793 - val_acc: 0.7270\n",
      "Epoch 24/50\n",
      "3429/3429 [==============================] - 0s 79us/step - loss: 0.9850 - acc: 0.6500 - val_loss: 0.8275 - val_acc: 0.7297\n",
      "Epoch 25/50\n",
      "3429/3429 [==============================] - 0s 82us/step - loss: 0.9868 - acc: 0.6425 - val_loss: 0.8345 - val_acc: 0.7139\n",
      "Epoch 26/50\n",
      "3429/3429 [==============================] - 0s 81us/step - loss: 0.9486 - acc: 0.6535 - val_loss: 0.8265 - val_acc: 0.7192\n",
      "Epoch 27/50\n",
      "3429/3429 [==============================] - 0s 81us/step - loss: 0.9519 - acc: 0.6597 - val_loss: 0.8121 - val_acc: 0.6955\n",
      "Epoch 28/50\n",
      "3429/3429 [==============================] - 0s 78us/step - loss: 0.9408 - acc: 0.6635 - val_loss: 0.7527 - val_acc: 0.7428\n",
      "Epoch 29/50\n",
      "3429/3429 [==============================] - 0s 80us/step - loss: 0.9676 - acc: 0.6492 - val_loss: 0.7892 - val_acc: 0.7060\n",
      "Epoch 30/50\n",
      "3429/3429 [==============================] - 0s 83us/step - loss: 0.9425 - acc: 0.6646 - val_loss: 0.7599 - val_acc: 0.7349\n",
      "Epoch 31/50\n",
      "3429/3429 [==============================] - 0s 80us/step - loss: 0.9462 - acc: 0.6538 - val_loss: 0.7938 - val_acc: 0.7270\n",
      "Epoch 32/50\n",
      "3429/3429 [==============================] - 0s 79us/step - loss: 0.9336 - acc: 0.6579 - val_loss: 0.8210 - val_acc: 0.7113\n",
      "Epoch 33/50\n",
      "3429/3429 [==============================] - 0s 80us/step - loss: 0.9497 - acc: 0.6655 - val_loss: 0.7845 - val_acc: 0.7165\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "                    batch_size=32,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(val_x, val_y),callbacks=[early_stopping,save_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "c3196d0f40b7360d155641dca87ec54fe09a311a"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_df)\n",
    "prediction=np.argmax(prediction, axis=1) \n",
    "submission = pd.read_csv(\"Data/sample_submission.csv\")\n",
    "submission['surface'] = le.inverse_transform(prediction)\n",
    "submission.to_csv('cnn_74.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "29a475b0a67880ec93e8b7f6425949847e718852"
   },
   "outputs": [],
   "source": [
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "val_x = np.reshape(val_x, (val_x.shape[0], val_x.shape[1], 1))\n",
    "test_df = np.reshape(test_df, (test_df.shape[0], test_df.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "cb86bccfe0416b09b58a91e77dee577ad37ae6f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 165, 165)          330       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 82, 165)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 82, 165)           0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 82, 128)           21248     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 82, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 61,011\n",
      "Trainable params: 61,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Creating the model\n",
    "model = Sequential()\n",
    "\n",
    "# Inputing the first layer with input dimensions\n",
    "model.add(Dense(165,activation='relu',input_shape = (nb_features,1),kernel_initializer='uniform'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "# Adding an Dropout layer to previne from overfitting\n",
    "model.add(Dropout(0.50))\n",
    "#adding second hidden layer \n",
    "model.add(Dense(128,kernel_initializer='uniform',activation='relu'))\n",
    "# Adding another Dropout layer\n",
    "model.add(Dropout(0.50))\n",
    "model.add(GRU(64))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(32,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "# adding the output layer that is binary [0,1]\n",
    "model.add(Dense(nb_out, activation='softmax'))\n",
    "#Visualizing the model\n",
    "model.summary()\n",
    "sgd = SGD(lr = 0.01, momentum = 0.9)\n",
    "# Compiling our model\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min')\n",
    "save_best = ModelCheckpoint('cnn.hdf', save_best_only=True,monitor='val_loss', mode='min')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "5e3f14c4bbd2ef411d92e63d4b86397f1b263a24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3429 samples, validate on 381 samples\n",
      "Epoch 1/10\n",
      "3429/3429 [==============================] - 12s 4ms/step - loss: 2.0921 - acc: 0.1966 - val_loss: 2.0366 - val_acc: 0.2021\n",
      "Epoch 2/10\n",
      "3429/3429 [==============================] - 10s 3ms/step - loss: 2.0332 - acc: 0.2006 - val_loss: 2.0279 - val_acc: 0.1916\n",
      "Epoch 3/10\n",
      "3429/3429 [==============================] - 11s 3ms/step - loss: 2.0222 - acc: 0.1910 - val_loss: 2.0196 - val_acc: 0.2021\n",
      "Epoch 4/10\n",
      "3429/3429 [==============================] - 11s 3ms/step - loss: 2.0193 - acc: 0.1980 - val_loss: 2.0136 - val_acc: 0.2021\n",
      "Epoch 5/10\n",
      "3429/3429 [==============================] - 10s 3ms/step - loss: 2.0118 - acc: 0.2152 - val_loss: 2.0102 - val_acc: 0.2021\n",
      "Epoch 6/10\n",
      "3429/3429 [==============================] - 12s 4ms/step - loss: 2.0085 - acc: 0.2138 - val_loss: 1.9970 - val_acc: 0.2336\n",
      "Epoch 7/10\n",
      "3429/3429 [==============================] - 10s 3ms/step - loss: 1.9913 - acc: 0.2482 - val_loss: 1.9666 - val_acc: 0.2520\n",
      "Epoch 8/10\n",
      "3429/3429 [==============================] - 10s 3ms/step - loss: 1.9570 - acc: 0.2718 - val_loss: 1.9272 - val_acc: 0.2808\n",
      "Epoch 9/10\n",
      "3429/3429 [==============================] - 10s 3ms/step - loss: 1.9306 - acc: 0.2776 - val_loss: 1.8986 - val_acc: 0.2808\n",
      "Epoch 10/10\n",
      "3429/3429 [==============================] - 11s 3ms/step - loss: 1.8853 - acc: 0.3013 - val_loss: 1.8521 - val_acc: 0.3228\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(val_x, val_y),callbacks=[early_stopping,save_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "969384c9bfd2f2c974149de2f5982f5555186ea1"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_df)\n",
    "prediction=np.argmax(prediction, axis=1) \n",
    "submission = pd.read_csv(\"Data/sample_submission.csv\")\n",
    "submission['surface'] = le.inverse_transform(prediction)\n",
    "submission.to_csv('gru_33.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "29c6426612838084f7f1ae79bbecd02ea5a22736"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
